{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModeloPredicción.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ESTUDIO DE FACTORES DE MOTIVACIÓN EN LA COMPRA DE UN VEHÍCULO ELÉCTRICO Y LA IMPLANTACIÓN MASIVA DE ESTOS ENTRE LOS CONDUCTORES\n",
        "## ELENA DELGADO DEL REY \n",
        "## TRABAJO FIN DE GRADO"
      ],
      "metadata": {
        "id": "dsuEQ5GfZTsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este trabajo va sobre los coches eléctricos que se encuentran actualmente en el mercado. En el DataSet utilizado tenemos información de la marca del coche, su modelo, precio, etc..."
      ],
      "metadata": {
        "id": "JVJLJxdgZkB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPARAR EL ENTORNO"
      ],
      "metadata": {
        "id": "9ZGeVgNfZO81"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "id": "c4TlKVuoW7YL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np      \n",
        "!pip install -q pyspark\n",
        "%matplotlib inline\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "import pyspark\n",
        "findspark.find()\n",
        "import pyspark\n",
        "from pyspark.sql.session import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as func\n",
        "from pyspark.sql.functions import col\n",
        "import pyspark.sql.types as typ\n",
        "import pyspark.ml.feature as ft\n",
        "import pyspark.ml.regression as rg\n",
        "from pyspark.ml import Pipeline\n",
        "import pyspark.ml.evaluation as ev\n",
        "from pyspark.ml.param import Param, Params\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "import pyspark.ml.regression\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "import pyspark.ml.tuning as tune\n",
        "import numpy as np\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.ml.feature import ChiSqSelector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "exec(open(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py')).read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91pNjaJ6Xh_e",
        "outputId": "7a2752db-0fdb-43eb-e0f0-ae4c148e0022"
      },
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.3.0\n",
            "      /_/\n",
            "\n",
            "Using Python version 3.7.13 (default, Apr 24 2022 01:04:09)\n",
            "Spark context Web UI available at http://fb5eb0219f58:4040\n",
            "Spark context available as 'sc' (master = local[*], app id = local-1656521760155).\n",
            "SparkSession available as 'spark'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics as stats\n",
        "%matplotlib inline \n",
        "sns.set_palette('pastel')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors as mcolors\n",
        "import pandas.util.testing as tm\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "0vy3WlKDZrHR"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTAMOS EL CSV QUE SE HA LIMPIADO Y UNIFICADO PREVIAMENTE"
      ],
      "metadata": {
        "id": "Blyk3J2sZIWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "# para utilizar lo que tengo en google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmAO1hi8Zmxc",
        "outputId": "ad149a1f-131e-4019-bc02-50a597fc5d1a"
      },
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "O6JoTaPWcrwB"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero vamos a importar el csv, indicandole que los datos estan separados con  ; y que la primera columna es el header del dataframe"
      ],
      "metadata": {
        "id": "dyCg_Hh2Uqqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coches_df = spark.read.csv(\"/content/drive/MyDrive/Cuarto/TFG/Coches/DatasetVE.csv\", header='true', inferSchema='false', schema=schema, sep=';')"
      ],
      "metadata": {
        "id": "HemkGYnxfkPl"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coches_df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrQg_T1Ofwxz",
        "outputId": "866d235d-b701-4827-d9c5-b41990390105"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, MARCA1='VOLKSWAGEN', MODELO='ID. BUZZ', Ventas total=6323, Precio=55000, range km=340, tiempo=10.0, kWh=77.0, eficiencia Wh/km=226, cargarapida km/h=510, velocidadmax km/h=145, Segment_num=7, marketsegment='N', personas=4, towingcapacity=1134, motor='Battery Electric Vehicle ', url='https://ev-database.org/car/1651/1-ID-Buzz')]"
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a visualizar el esquema, para entender de que tipo sn las variables"
      ],
      "metadata": {
        "id": "R6dsmDWpUzK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coches_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "446eno3Nf0qD",
        "outputId": "a8713b29-6c70-40ea-b398-ff0f34ef6d16"
      },
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Marca0: integer (nullable = true)\n",
            " |-- MARCA1: string (nullable = true)\n",
            " |-- MODELO: string (nullable = true)\n",
            " |-- Ventas total: integer (nullable = true)\n",
            " |-- Precio: integer (nullable = true)\n",
            " |-- range km: integer (nullable = true)\n",
            " |-- tiempo: double (nullable = true)\n",
            " |-- kWh: double (nullable = true)\n",
            " |-- eficiencia Wh/km: integer (nullable = true)\n",
            " |-- cargarapida km/h: integer (nullable = true)\n",
            " |-- velocidadmax km/h: integer (nullable = true)\n",
            " |-- Segment_num: integer (nullable = true)\n",
            " |-- marketsegment: string (nullable = true)\n",
            " |-- personas: integer (nullable = true)\n",
            " |-- towingcapacity: integer (nullable = true)\n",
            " |-- motor: string (nullable = true)\n",
            " |-- url: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, vamos a crear un nuevo dataframe indicandole únicamente las variables que vamos a querer utilizar en los modelos. Teniendo en cuenta que al ser regressores las variables tienen que ser númericas"
      ],
      "metadata": {
        "id": "FXagBEzuU3ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cochesnuevo=coches_df.select(\"Marca0\",\"Ventas total\",\"Precio\",\"range km\",\"tiempo\",\"kWh\",\"eficiencia Wh/km\",\"cargarapida km/h\",\"velocidadmax km/h\",\"Segment_num\",\"personas\")"
      ],
      "metadata": {
        "id": "B6A_nWxUf4vG"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cochesnuevo.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8MABhhVgdRt",
        "outputId": "2bb48a43-b7c2-420e-87d6-b5a6d0b4f89a"
      },
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+------+--------+------+----+----------------+----------------+-----------------+-----------+--------+\n",
            "|Marca0|Ventas total|Precio|range km|tiempo| kWh|eficiencia Wh/km|cargarapida km/h|velocidadmax km/h|Segment_num|personas|\n",
            "+------+------------+------+--------+------+----+----------------+----------------+-----------------+-----------+--------+\n",
            "|     1|        6323| 55000|     340|  10.0|77.0|             226|             510|              145|          7|       4|\n",
            "|     1|        6323| 47740|     410|   8.5|77.0|             188|             520|              160|          3|       5|\n",
            "|     1|        6323| 36890|     350|   9.6|58.0|             166|             490|              160|          3|       4|\n",
            "|     1|        6323| 53790|     400|   6.2|77.0|             193|             500|              180|          3|       5|\n",
            "|     1|        6323| 26895|     205|  11.9|32.3|             158|             170|              130|          1|       4|\n",
            "|     1|        6323| 38390|     350|   7.3|58.0|             166|             490|              160|          3|       4|\n",
            "|     1|        6323| 42690|     450|   7.9|77.0|             171|             570|              160|          3|       4|\n",
            "|     1|        6323| 55690|     405|   6.3|77.0|             190|             540|              180|          3|       5|\n",
            "|     1|        6323| 43807|     410|  10.4|77.0|             188|             520|              160|          3|       5|\n",
            "|     1|        6323| 39790|     285|  10.9|52.0|             182|             360|              160|          3|       5|\n",
            "|     1|        6323| 48590|     430|  10.4|77.0|             179|             540|              160|          3|       5|\n",
            "|     1|        6323| 33990|     275|   8.9|45.0|             164|             410|              160|          3|       4|\n",
            "|     1|        6323| 42460|     450|   7.9|77.0|             171|             570|              160|          3|       4|\n",
            "|     1|        6323| 50090|     430|   8.4|77.0|             179|             540|              160|          3|       5|\n",
            "|     1|        6323| 41290|     285|   9.0|52.0|             182|             360|              160|          3|       5|\n",
            "|     2|        6322| 55500|     370|   5.2|70.0|             189|             910|              185|          3|       5|\n",
            "|     2|        6322| 55500|     385|   5.2|72.5|             188|            1010|              185|          3|       5|\n",
            "|     3|        9144| 60995|     485|   4.4|75.0|             155|             670|              233|          4|       5|\n",
            "|     4|        3393| 60630|     470|   5.7|80.7|             172|             650|              190|          4|       5|\n",
            "|     3|        9144| 52995|     380|   6.1|57.5|             151|             590|              225|          4|       5|\n",
            "+------+------------+------+--------+------+----+----------------+----------------+-----------------+-----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tenemos todos los Datasets revisados, vamos a entrenar nuestro modelo. Como nuestro Dataset no fue sacado de los challenges y nuestro proposito desde que empezamos a manejar los datos fue predecir el precio futuro de un coche, ahora vamos a estudiar con métodos de predicción adecuados los precios."
      ],
      "metadata": {
        "id": "eqCjyz6rJ5dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELOS DE APRENDIZAJE"
      ],
      "metadata": {
        "id": "YkyLcyP6keMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.ml.feature as ft\n",
        "import pyspark.ml.regression as rg\n",
        "from pyspark.ml import Pipeline\n",
        "import pyspark.ml.evaluation as ev\n",
        "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.param import Param, Params"
      ],
      "metadata": {
        "id": "VPWklm3gJ9sJ"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un modelo de regresión es un modelo matemático que busca determinar la relación entre una variable dependiente (Y) con respecto a otras variables llamadas explicativas o independientes (X). Asimismo, el modelo busca determinar cuál será el impacto sobre la variable Y ante un cambio en las variables explicativas (X)."
      ],
      "metadata": {
        "id": "F9aBaN1ZKASy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puesto que nosotros tenemos que hacer una regresión, vamos a ver que métodos de entrenamiento tenemos. \n",
        "+ Linear regression\n",
        "+ Decision tree regression\n",
        "+ Random forest regression\n",
        "+ Gradient-boosted tree regression\n",
        "+ Isotonic regression"
      ],
      "metadata": {
        "id": "Q9xsXVrJKCLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIVISIÓN DE DATOS"
      ],
      "metadata": {
        "id": "cmBH0JnJKI_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a dividir los datos, 80 % va a ser de los datos de entrenamiento y el otro 20 % es para los datos de test. Ambos que luego se usaran para entrenar el modelo"
      ],
      "metadata": {
        "id": "gdnew_oUKNBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets (20% held out for testing)\n",
        "(trainingData, testData) = cochesnuevo.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "vSi7hN2lKPGx"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de comenzar, vamos a pasar nuestra columna de price para que sea de DoubleType y así podamos usarla en los modelos."
      ],
      "metadata": {
        "id": "Eq7wD8VsKRG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cochesnuevo = cochesnuevo.withColumn('Precio', cochesnuevo['Precio'].cast(typ.DoubleType()))"
      ],
      "metadata": {
        "id": "msufiLAZKSwk"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASOS A SEGUIR PARA CREAR PREDICCIONES "
      ],
      "metadata": {
        "id": "I6gyJkZoKWqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Para realizar este algoritmo vamos a empezar creando una columna que reúna todas las variables utilizando los **transformadores**.\n",
        "2. Preparar nuestro **modelo** con sus respectivos valores en caso de tener.\n",
        "3. Creamos el **pipeline**. El Pipeline nos va a ayudar a meter nuestros transformadores y el modelo para ejecutarlo uno detrás de otro.\n",
        "4. **Modelamos** nuestros datos de training el cual tiene el 80% de nuestros datos.\n",
        "5. A continuación **testeamos** el modelo \n",
        "6. **Visualizamos** las predicciones que hemos obtenido.\n",
        "7. **Evaluamos** el modelo \n",
        "8. Calculamos el **RMSE** (raíz del error cuadrático medio) y el **MSE** (error cuadrático medio)  de nuestro modelo. "
      ],
      "metadata": {
        "id": "u86kWsyzKbaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RANDOM FOREST**"
      ],
      "metadata": {
        "id": "JUOsvwr1lJaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor"
      ],
      "metadata": {
        "id": "MCBdxQmNKpST"
      },
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer algoritmo ES Random Forest ya que este algoritmo de regresión consiste en un conjunto de múltiples árboles de decisión independientes, al cual se le asigna un conjunto de datos aleatorios con una misma distribución. La salida es el promedio de los resultados finales de cada árbol."
      ],
      "metadata": {
        "id": "5vJPr82SKrAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el estimador en nuestro caso es un modelo de tipo Regresión y escogemos el Random Forest"
      ],
      "metadata": {
        "id": "E5pv4lIflK0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest:es un método en nuestro caso para regresión, contruyendo multiplos árboles de decision y te crea una multiplicación."
      ],
      "metadata": {
        "id": "G3pSMTo0lNsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a empezar creando una columna que reúna todas las variables utilizando el transformador VectorAssembler."
      ],
      "metadata": {
        "id": "DF6_D9o8K0II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mivectorRF = ft.VectorAssembler(\n",
        "    inputCols=[\"Marca0\",\"Ventas total\",\"range km\",\"tiempo\",\"kWh\",\"eficiencia Wh/km\",\"cargarapida km/h\",\"velocidadmax km/h\",\"Segment_num\",\"personas\"], \n",
        "    outputCol='features'\n",
        ")"
      ],
      "metadata": {
        "id": "hsSM0SPglrcD"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Ahora vamos a preparar nuestro modelo con sus valores:\n",
        "    + 5 árboles para entrenar nuestros datos\n",
        "    + 5 niveles de profundidad de los árboles\n",
        "    + 'price', la columna que tiene que predecir"
      ],
      "metadata": {
        "id": "Ma8HLCapK4nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "algoritmoRF = rg.RandomForestRegressor(\n",
        "    numTrees=5, \n",
        "    maxDepth=5, \n",
        "    labelCol='Precio')"
      ],
      "metadata": {
        "id": "9mDQMUvam_dG"
      },
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el Pipeline ya que nos va a ayudar a meter nuestro VectorAssembler y el modelo para ejecutarlo uno detrás de otro."
      ],
      "metadata": {
        "id": "GsIQRARJK8wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipelineRF = Pipeline(stages=[mivectorRF, algoritmoRF])"
      ],
      "metadata": {
        "id": "4iuvkh0MnA_2"
      },
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelamos nuestros datos de training el cual tiene el 80% de nuestros datos."
      ],
      "metadata": {
        "id": "FDxOmVHLK_BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelRF = pipelineRF.fit(trainingData)"
      ],
      "metadata": {
        "id": "rOPzq5l8nDus"
      },
      "execution_count": 428,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a poner al modelo a que haga las prediciones con los datos."
      ],
      "metadata": {
        "id": "gjUsSWZ4LDNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testRF = modelRF.transform(testData)"
      ],
      "metadata": {
        "id": "8cCtsctTGa_q"
      },
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos las dos primeras columnas para ver que prediccion nos ha hecho nuestro modelo."
      ],
      "metadata": {
        "id": "cf_umqQPLFsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testRF.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sobOJAYgGcau",
        "outputId": "9a750fd7-74c2-47ce-8474-a21f81102686"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, Ventas total=6323, Precio=42460.0, range km=450, tiempo=7.9, kWh=77.0, eficiencia Wh/km=171, cargarapida km/h=570, velocidadmax km/h=160, Segment_num=3, personas=4, features=DenseVector([1.0, 6323.0, 450.0, 7.9, 77.0, 171.0, 570.0, 160.0, 3.0, 4.0]), prediction=44951.26741234425),\n",
              " Row(Marca0=1, Ventas total=6323, Precio=43807.0, range km=410, tiempo=10.4, kWh=77.0, eficiencia Wh/km=188, cargarapida km/h=520, velocidadmax km/h=160, Segment_num=3, personas=5, features=DenseVector([1.0, 6323.0, 410.0, 10.4, 77.0, 188.0, 520.0, 160.0, 3.0, 5.0]), prediction=53889.599204126745)]"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a evaluar nuestro modelo para ver la raíz del error cuadratico medio RMSE, y el error cuadrático medio MSE."
      ],
      "metadata": {
        "id": "eyleuoAeLJ_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Precio\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmseRF = evaluator.evaluate(testRF)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmseRF) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-YdKaS4GeLE",
        "outputId": "7acfa001-53e0-4b08-fb47-c80c44b17856"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 32453.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mseRF = rmseRF*rmseRF\n",
        "print(\"Mean Squared Error (MSE) on test data = %g\" % mseRF) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQOR1ZlXLP6t",
        "outputId": "8e6e5dcc-408d-412c-ad53-135e656335ba"
      },
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) on test data = 1.05323e+09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GRADIENT BOOSTED TREE CLASSIFIER**"
      ],
      "metadata": {
        "id": "R0RQk7jgGqMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import GBTRegressor"
      ],
      "metadata": {
        "id": "SMD81leyLhfl"
      },
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosted Tree Regressor es una técnica de aprendizaje automático que produce un modelo de predicción en forma de un conjunto de modelos de predicción débiles, típicamente árboles de decisión. En estos casos, construye cada árbol de regresión de forma gradual, utilizando una función de pérdida predefinida para medir el error en cada paso y corregirlo en el siguiente."
      ],
      "metadata": {
        "id": "KUsaEKpOLj4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Habiendo visto que Random Forest no es un modelo adecuado para nuestros datos, se va a comprobar si este modelo nos proporciona mejores predicciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "oyew2B0uLmN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el estimador en nuestro caso es un modelo de tipo Regresión y escogemos el Gradient Boosted Tree Classifier"
      ],
      "metadata": {
        "id": "WQszmqDcGuQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gracient Boosted Tree Classifier: es un grupo de algoritmos que combina métodos juntos para crear un modelo de predicción. "
      ],
      "metadata": {
        "id": "RZ1yGQlqGwS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que con el método anterior, vamos a empezar creando una columna que reúna todas las variables utilizando transformadores."
      ],
      "metadata": {
        "id": "rE9_4pwvNTjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresCols = cochesnuevo.columns"
      ],
      "metadata": {
        "id": "Y2M_HdpWAGsg"
      },
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mivectorGBT = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")"
      ],
      "metadata": {
        "id": "U4utkHozAIwL"
      },
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This identifies categorical features and indexes them.\n",
        "vectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=4)"
      ],
      "metadata": {
        "id": "fdUbO7v9AL-_"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparamos el modelo con columna a predecir 'price'"
      ],
      "metadata": {
        "id": "PcH1QJziNdVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the \"features\" column and learns to predict \"hotel_cluster\"\n",
        "gbt = GBTRegressor(labelCol=\"Precio\")"
      ],
      "metadata": {
        "id": "oFMMI_4JAOi2"
      },
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el pipeline para ejecutar nuestro VectorAssembler, el VectorIndexer y el modelo uno detrás de otro."
      ],
      "metadata": {
        "id": "ToqUm5pFNmel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipelineGBT = Pipeline(stages=[mivectorGBT, vectorIndexer, gbt])"
      ],
      "metadata": {
        "id": "31nepk8sATD4"
      },
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos el modelado de nuestros datos de training (80% de los datos)."
      ],
      "metadata": {
        "id": "hit6jPO8N71x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modeloGBT = pipelineGBT.fit(trainingData)"
      ],
      "metadata": {
        "id": "5sEOWCd4AVMS"
      },
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo con los datos de test (20%)"
      ],
      "metadata": {
        "id": "NZZcj53bN_L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testGBT = modeloGBT.transform(testData)"
      ],
      "metadata": {
        "id": "WKD3nvqLHC5p"
      },
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos las dos primeras prediciones para ver como ha funcionado nuestro modelo"
      ],
      "metadata": {
        "id": "IxWPAc7KOLqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testGBT.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZFBeK2yHEs8",
        "outputId": "7cd8ce7d-96ba-4dbb-c692-4b8eb8f5f80b"
      },
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, Ventas total=6323, Precio=42460.0, range km=450, tiempo=7.9, kWh=77.0, eficiencia Wh/km=171, cargarapida km/h=570, velocidadmax km/h=160, Segment_num=3, personas=4, rawFeatures=DenseVector([1.0, 6323.0, 42460.0, 450.0, 7.9, 77.0, 171.0, 570.0, 160.0, 3.0, 4.0]), features=DenseVector([1.0, 6323.0, 42460.0, 450.0, 7.9, 77.0, 171.0, 570.0, 160.0, 3.0, 4.0]), prediction=43201.14237522483),\n",
              " Row(Marca0=1, Ventas total=6323, Precio=43807.0, range km=410, tiempo=10.4, kWh=77.0, eficiencia Wh/km=188, cargarapida km/h=520, velocidadmax km/h=160, Segment_num=3, personas=5, rawFeatures=DenseVector([1.0, 6323.0, 43807.0, 410.0, 10.4, 77.0, 188.0, 520.0, 160.0, 3.0, 5.0]), features=DenseVector([1.0, 6323.0, 43807.0, 410.0, 10.4, 77.0, 188.0, 520.0, 160.0, 3.0, 5.0]), prediction=44369.604280154104)]"
            ]
          },
          "metadata": {},
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluamos la precisión de predicción de nuestro modelo con un RegressionEvaluator"
      ],
      "metadata": {
        "id": "QZlKas9SOOft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Precio\", predictionCol=\"prediction\", metricName=\"rmse\")"
      ],
      "metadata": {
        "id": "qIpq7V9pHHuV"
      },
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el RMSE (raíz del error cuadrático medio) y el MSE (error cuadrático medio) de nuestro modelo."
      ],
      "metadata": {
        "id": "EiVDQyROORmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmseGBT = evaluator.evaluate(testGBT)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmseGBT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7yOJVEAHJv_",
        "outputId": "eae4dc77-f99e-4cf6-ed50-48a68e68f2ea"
      },
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 5520.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mseGBT = rmseGBT*rmseGBT\n",
        "print(\"Mean Squared Error (MSE) on test data = %g\" % mseGBT) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajpCW8zeHMfk",
        "outputId": "c1e7733a-9c3f-4c02-ce17-eb371049761e"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) on test data = 3.04763e+07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LINEAR REGRESSION**"
      ],
      "metadata": {
        "id": "aYyyK_qVHOLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "g0D8DnDQOk0Z"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression es una técnica estadística donde podemos identificar que variables independientes (causas) explican una variable dependiente (resultado)."
      ],
      "metadata": {
        "id": "4oHvgd6XO8Jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el estimador en nuestro caso es un modelo de tipo Regresión y escogemos el Linear Regression"
      ],
      "metadata": {
        "id": "_Qk5_UXaHPvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression: es un enfoque linear para modelar la relación entre dos escalares (variables dependientes) y una o mas varibles independientes"
      ],
      "metadata": {
        "id": "NH-8J8myHR6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzamos creando una columna que reúna todas las variables utilizando el transformador VectorAssembler. A esta columna la llamaremos 'rawFeatures'"
      ],
      "metadata": {
        "id": "blk3wI7nO-E4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mivectorLR = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")"
      ],
      "metadata": {
        "id": "RRq9t3vBHTrl"
      },
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This identifies categorical features and indexes them.\n",
        "vectorIndexerLR = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=4)"
      ],
      "metadata": {
        "id": "u-Pbtc5hHWPd"
      },
      "execution_count": 452,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montamos el modelo de Linear Regresision para predecir la columna 'price'"
      ],
      "metadata": {
        "id": "vRQ-cccDPGep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the \"features\" column and learns to predict \"price_cluster\"\n",
        "lr = LinearRegression(labelCol=\"Precio\")"
      ],
      "metadata": {
        "id": "sw-JokgIHYun"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que los casos anteriores, creamos el pipeline para ejecutar nuestro VectorAssembler, el VectorIndexer y el modelo uno detrás de otro."
      ],
      "metadata": {
        "id": "q79nf2jiPL6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipelineLR = Pipeline(stages=[mivectorLR, vectorIndexerLR, lr])"
      ],
      "metadata": {
        "id": "sFN-lO8KHcjv"
      },
      "execution_count": 453,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos el modelado del 80% de los datos y entrenamos el modelo con el 20% restante"
      ],
      "metadata": {
        "id": "V1pgX51bPQUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelLR = pipelineLR.fit(trainingData)"
      ],
      "metadata": {
        "id": "XVcjEPtvHfif"
      },
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testLR = modelLR.transform(testData)"
      ],
      "metadata": {
        "id": "OI6-HgdLHhOE"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos las dos primeras prediciones para ver como ha funcionado nuestro modelo"
      ],
      "metadata": {
        "id": "IB0xGQS6Pa4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testLR.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It0gyqjKHhYt",
        "outputId": "69dad71b-7318-4de1-9224-9e1d1a6e518d"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, Ventas total=6323, Precio=42460.0, range km=450, tiempo=7.9, kWh=77.0, eficiencia Wh/km=171, cargarapida km/h=570, velocidadmax km/h=160, Segment_num=3, personas=4, rawFeatures=DenseVector([1.0, 6323.0, 42460.0, 450.0, 7.9, 77.0, 171.0, 570.0, 160.0, 3.0, 4.0]), features=DenseVector([1.0, 6323.0, 42460.0, 450.0, 7.9, 77.0, 171.0, 570.0, 160.0, 3.0, 4.0]), prediction=42459.67155366662),\n",
              " Row(Marca0=1, Ventas total=6323, Precio=43807.0, range km=410, tiempo=10.4, kWh=77.0, eficiencia Wh/km=188, cargarapida km/h=520, velocidadmax km/h=160, Segment_num=3, personas=5, rawFeatures=DenseVector([1.0, 6323.0, 43807.0, 410.0, 10.4, 77.0, 188.0, 520.0, 160.0, 3.0, 5.0]), features=DenseVector([1.0, 6323.0, 43807.0, 410.0, 10.4, 77.0, 188.0, 520.0, 160.0, 3.0, 5.0]), prediction=43807.47859376746)]"
            ]
          },
          "metadata": {},
          "execution_count": 457
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluamos la precisión de predicción de nuestro modelo con un RegressionEvaluator. Al ver que las predicciones de linear regression son bastante parecidas a las originales podemos suponer que el error cuadrático medio será muy bajo."
      ],
      "metadata": {
        "id": "h4KVf6mxPeWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Precio\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmseLR = evaluator.evaluate(testLR)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmseLR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hjPP5MZHmzt",
        "outputId": "f2888448-3f41-4522-fe18-cc10f505d02b"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 5.27958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el MSE (error cuadrático medio) de nuestro modelo."
      ],
      "metadata": {
        "id": "kWjWbVtxPw_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mseLR = rmseLR*rmseLR\n",
        "print(\"Mean Squared Error (MSE) on test data = %g\" % mseLR) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP2T5t_gHpvW",
        "outputId": "572d16c9-0c47-4168-a7e4-8cbcb470e9e3"
      },
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) on test data = 27.8739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GRID SEARCH de random forest**"
      ],
      "metadata": {
        "id": "TZeXIBQiHr4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a hacer un grid search de random forest para ver que parametros son los mejores para la prediccion de datos.Grid search es el proceso de escanear los datos para configurar parámetros óptimos para un modelo dado. Grid-Search creará un modelo en cada combinación de parámetros posible. Recorre cada combinación de parámetros y almacena un modelo para cada combinación."
      ],
      "metadata": {
        "id": "aK9Hr1QBQWMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.ml.regression as rg\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "forest =  rg.RandomForestRegressor(labelCol='Precio')\n",
        "\n",
        "grid = tune.ParamGridBuilder().addGrid(forest.numTrees, [2, 5]).addGrid(forest.maxDepth, [5, 3]).build()"
      ],
      "metadata": {
        "id": "a9HmP344HtUo"
      },
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator =RegressionEvaluator(predictionCol='prediction', labelCol='Precio')"
      ],
      "metadata": {
        "id": "6qvzFWNQHxsX"
      },
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgC = tune.CrossValidator(estimator=forest, estimatorParamMaps=grid, evaluator=evaluator)"
      ],
      "metadata": {
        "id": "2O7Oq-l0H0a0"
      },
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[mivectorRF])\n",
        "data_transformer = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "xBpr_N4uH2XV"
      },
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transformer = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "H9DQqIQPH3HO"
      },
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgModel = rgC.fit(data_transformer.transform(trainingData))"
      ],
      "metadata": {
        "id": "hMtywyEFH44D"
      },
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_transformer.transform(testData)"
      ],
      "metadata": {
        "id": "pbEW2WIIH7Ca"
      },
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = rgModel.transform(data_train)"
      ],
      "metadata": {
        "id": "KrtmqbrvH8k-"
      },
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy7K1XJpH_jp",
        "outputId": "71e652fc-ed63-4c03-8da9-02dad7f89cb6"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, Ventas total=6323, Precio=42460.0, range km=450, tiempo=7.9, kWh=77.0, eficiencia Wh/km=171, cargarapida km/h=570, velocidadmax km/h=160, Segment_num=3, personas=4, features=DenseVector([1.0, 6323.0, 450.0, 7.9, 77.0, 171.0, 570.0, 160.0, 3.0, 4.0]), prediction=46604.3789890374),\n",
              " Row(Marca0=1, Ventas total=6323, Precio=43807.0, range km=410, tiempo=10.4, kWh=77.0, eficiencia Wh/km=188, cargarapida km/h=520, velocidadmax km/h=160, Segment_num=3, personas=5, features=DenseVector([1.0, 6323.0, 410.0, 10.4, 77.0, 188.0, 520.0, 160.0, 3.0, 5.0]), prediction=53406.180373087875)]"
            ]
          },
          "metadata": {},
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Precio\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmseGS = evaluator.evaluate(results)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmseGS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXz6ls4GICPf",
        "outputId": "109b6fe2-1af7-487b-9f36-0ac65415821d"
      },
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 24814.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mseGS = rmseGS*rmseGS\n",
        "print(\"Mean Squared Error (MSE) on test data = %g\" % mseGS) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAVC9H-6Qrn2",
        "outputId": "018c7f9a-9ce4-4ab7-e863-9670254bfcf9"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) on test data = 6.15758e+08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que, aunque tenga los parametros más adecuados, el error de predicción sigue siendo muy alto, por lo que esto nos confirma que Random Forest NO es el método adecuado para nuestros datos"
      ],
      "metadata": {
        "id": "5eyQ49mJQt8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = [\n",
        "    (\n",
        "        [\n",
        "            {key.name: paramValue} \n",
        "            for key, paramValue \n",
        "            in zip(\n",
        "                params.keys(), \n",
        "                params.values())\n",
        "        ], metric\n",
        "    ) \n",
        "    for params, metric \n",
        "    in zip(\n",
        "        rgModel.getEstimatorParamMaps(), \n",
        "        rgModel.avgMetrics\n",
        "    )\n",
        "]\n",
        "\n",
        "sorted(results, key=lambda el: el[1], reverse=True)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vldYMpdIGbN",
        "outputId": "d870469d-936d-4f93-ccf6-b24e92c2b5ae"
      },
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{'numTrees': 2}, {'maxDepth': 5}], 31970.50331774612)"
            ]
          },
          "metadata": {},
          "execution_count": 475
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver el RMSE ha bajado para el Random Forest"
      ],
      "metadata": {
        "id": "BVXuukC_IJS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DISCRETIZAR VARIABLES CONTINUAS"
      ],
      "metadata": {
        "id": "SBlhZO8BRW4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discretizar datos quiere decir convertir variables que son continuas en variables agrupadas por intervalos. Esta operación simplifica la información agrupando los objetos geográficos que presentan las mismas características en distintas clases. Hemos discretizado la columna de Price, ya que esta al ser una medición es una variable contínua."
      ],
      "metadata": {
        "id": "4EU_zVG7Rb-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(0, 100)\n",
        "x = x / 100.0 * np.pi * 4\n",
        "y = x * np.sin(x / 1.764) + 20.1234\n",
        "\n",
        "schema = typ.StructType([\n",
        "    typ.StructField('Precio', \n",
        "                    typ.DoubleType(), \n",
        "                    False\n",
        "   )\n",
        "])\n",
        "\n",
        "data = sqlContext.createDataFrame([[float(e), ] for e in y], schema=schema)\n",
        "#data = spark.createDataFrame([[float(e), ] for e in y], schema=schema)"
      ],
      "metadata": {
        "id": "s__8NwV7Reu-"
      },
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a utilizar el QuantileDiscretizer para partir nuestra variable continua en 5 buckets"
      ],
      "metadata": {
        "id": "Eb5mnuFORkso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discretizer = ft.QuantileDiscretizer(\n",
        "    numBuckets=5, \n",
        "    inputCol='Precio', \n",
        "    outputCol='discretized')"
      ],
      "metadata": {
        "id": "6DhEeZdERmKh"
      },
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_discretized = discretizer.fit(cochesnuevo).transform(cochesnuevo)\n",
        "\n",
        "data_discretized \\\n",
        "    .groupby('discretized')\\\n",
        "    .mean('Precio')\\\n",
        "    .sort('discretized')\\\n",
        "    .collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mscm1EcRqEz",
        "outputId": "f2b5dd73-9e38-44c6-f325-44ca9b8cd07c"
      },
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(discretized=0.0, avg(Precio)=30761.204545454544),\n",
              " Row(discretized=1.0, avg(Precio)=43216.704545454544),\n",
              " Row(discretized=2.0, avg(Precio)=53590.568181818184),\n",
              " Row(discretized=3.0, avg(Precio)=63489.545454545456),\n",
              " Row(discretized=4.0, avg(Precio)=114160.51111111112)]"
            ]
          },
          "metadata": {},
          "execution_count": 479
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LINEAR REGRESSION DISCRETIZED**"
      ],
      "metadata": {
        "id": "WW5byMUDRxXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como Regresión Lineal es el algoritmo que mejor predicción nos ha dado, vamos a utilizarlo con los datos discretizados que acabamos de hallar."
      ],
      "metadata": {
        "id": "w9cX_HzMR2c1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al tener nuevos datos, debemos volver a separar nuestros datos en entrenamiento y test en un 80-20"
      ],
      "metadata": {
        "id": "5OaIi7NyR6G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingDataD, testDataD) = data_discretized.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "uR7J9zTeR7-6"
      },
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos los MISMOS PASOS que Linear Regressionn"
      ],
      "metadata": {
        "id": "qXjhiDaPR-1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelLRD = pipelineLR.fit(trainingDataD)"
      ],
      "metadata": {
        "id": "YeR3K982SAL8"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testLRD = modelLRD.transform(testDataD)"
      ],
      "metadata": {
        "id": "ya6odnC8SCDD"
      },
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testLRD.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsUeGBeJSCMN",
        "outputId": "9602c0f5-1084-4bc1-e609-4d5c778acffa"
      },
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, Ventas total=6323, Precio=38390.0, range km=350, tiempo=7.3, kWh=58.0, eficiencia Wh/km=166, cargarapida km/h=490, velocidadmax km/h=160, Segment_num=3, personas=4, discretized=0.0, rawFeatures=DenseVector([1.0, 6323.0, 38390.0, 350.0, 7.3, 58.0, 166.0, 490.0, 160.0, 3.0, 4.0]), features=DenseVector([1.0, 6323.0, 38390.0, 350.0, 7.3, 58.0, 166.0, 490.0, 160.0, 3.0, 4.0]), prediction=38391.17197737509),\n",
              " Row(Marca0=1, Ventas total=6323, Precio=55690.0, range km=405, tiempo=6.3, kWh=77.0, eficiencia Wh/km=190, cargarapida km/h=540, velocidadmax km/h=180, Segment_num=3, personas=5, discretized=2.0, rawFeatures=DenseVector([1.0, 6323.0, 55690.0, 405.0, 6.3, 77.0, 190.0, 540.0, 180.0, 3.0, 5.0]), features=DenseVector([1.0, 6323.0, 55690.0, 405.0, 6.3, 77.0, 190.0, 540.0, 180.0, 3.0, 5.0]), prediction=55689.331184753806)]"
            ]
          },
          "metadata": {},
          "execution_count": 483
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Precio\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmseLRD = evaluator.evaluate(testLRD)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmseLRD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbPp7jQgSGTY",
        "outputId": "981505d3-3152-4ac7-e36e-2d4c874efe9a"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 5.86492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mseLRD = rmseLRD*rmseLRD\n",
        "print(\"Mean Squared Error (MSE) on test data = %g\" % mseLRD) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COZfP15qSKZJ",
        "outputId": "18cd0ef9-87bf-44a1-e4ee-098d7e0434e0"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) on test data = 34.3973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESTANDARIZAR VARIABLES CONTINUAS"
      ],
      "metadata": {
        "id": "gmLx5uvbSOxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La estandarización o normalización de índices significa ajustar los valores medidos en diferentes escalas respecto a una escala común, a menudo previo a un proceso de realizar promedios."
      ],
      "metadata": {
        "id": "ARNbY6lQSUMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = ft.VectorAssembler(inputCols=['Precio'], outputCol= 'Precio_vec')"
      ],
      "metadata": {
        "id": "mYvZiKleSVhy"
      },
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos el \"normalizer\" y el \"pipeline\". Pondremos \"withMean=True\" y \"withStd=True\" para que la media y la varianza sean de un longitud de uno."
      ],
      "metadata": {
        "id": "lOfVWUWgSWxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = ft.StandardScaler(\n",
        "    inputCol=vectorizer.getOutputCol(), \n",
        "    outputCol='normalized', \n",
        "    withMean=True,\n",
        "    withStd=True\n",
        ")"
      ],
      "metadata": {
        "id": "hH6fhDIWSYoK"
      },
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[vectorizer, normalizer])\n",
        "data_standardized = pipeline.fit(cochesnuevo).transform(cochesnuevo)"
      ],
      "metadata": {
        "id": "9iAQUlrgScZQ"
      },
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_standardized.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rrfwt47SdHw",
        "outputId": "6249a1f2-3234-446d-a60d-a4364ea06c26"
      },
      "execution_count": 496,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, Ventas total=6323, Precio=55000.0, range km=340, tiempo=10.0, kWh=77.0, eficiencia Wh/km=226, cargarapida km/h=510, velocidadmax km/h=145, Segment_num=7, personas=4, Precio_vec=DenseVector([55000.0]), normalized=DenseVector([-0.1884]))]"
            ]
          },
          "metadata": {},
          "execution_count": 496
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LINEAR REGRESSIÓN STANDARIZED**"
      ],
      "metadata": {
        "id": "CJ4XJYxKSrKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en el caso anterior, vamos a utilizar Regresión Lineal ya que es el algoritmo que mejor predicción nos ha dado, por lo vamos a utilizarlo con los datos estandarizados que acabamos de hallar."
      ],
      "metadata": {
        "id": "o2EkQg_gSu0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingDataE, testDataE) = data_discretized.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "_5GGlM7-SxGO"
      },
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos los MISMOS PASOS que Linear Regressionn"
      ],
      "metadata": {
        "id": "0jsOwLChSy5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelLRE = pipelineLR.fit(trainingDataE)"
      ],
      "metadata": {
        "id": "DvCAcaHPSzoH"
      },
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testLRE = modelLRE.transform(testDataE)"
      ],
      "metadata": {
        "id": "HiJGZoCTS03R"
      },
      "execution_count": 499,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testLRE.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaV4OzhJS2Ey",
        "outputId": "8f0732aa-8097-4087-9660-b6d969cbd82c"
      },
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Marca0=1, Ventas total=6323, Precio=33990.0, range km=275, tiempo=8.9, kWh=45.0, eficiencia Wh/km=164, cargarapida km/h=410, velocidadmax km/h=160, Segment_num=3, personas=4, discretized=0.0, rawFeatures=DenseVector([1.0, 6323.0, 33990.0, 275.0, 8.9, 45.0, 164.0, 410.0, 160.0, 3.0, 4.0]), features=DenseVector([1.0, 6323.0, 33990.0, 275.0, 8.9, 45.0, 164.0, 410.0, 160.0, 3.0, 4.0]), prediction=33991.585923871506),\n",
              " Row(Marca0=1, Ventas total=6323, Precio=36890.0, range km=350, tiempo=9.6, kWh=58.0, eficiencia Wh/km=166, cargarapida km/h=490, velocidadmax km/h=160, Segment_num=3, personas=4, discretized=0.0, rawFeatures=DenseVector([1.0, 6323.0, 36890.0, 350.0, 9.6, 58.0, 166.0, 490.0, 160.0, 3.0, 4.0]), features=DenseVector([1.0, 6323.0, 36890.0, 350.0, 9.6, 58.0, 166.0, 490.0, 160.0, 3.0, 4.0]), prediction=36891.3268566916)]"
            ]
          },
          "metadata": {},
          "execution_count": 500
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZtmTU7FbUAZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Precio\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmseLRE = evaluator.evaluate(testLRE)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmseLRE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcv2DZ7LS40L",
        "outputId": "afcf66ae-af7f-47ee-dd10-b8fec26c6eaf"
      },
      "execution_count": 501,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 4.33176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mseLRE = rmseLRE*rmseLRE\n",
        "print(\"Mean Squared Error (MSE) on test data = %g\" % mseLRE) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDW0f5vmS67M",
        "outputId": "90d47706-b3f8-4165-b01f-cdfe9a89f7bd"
      },
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) on test data = 18.7641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMPARACIÓN RESULTADOS**"
      ],
      "metadata": {
        "id": "bMirtO5LUEev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RANDOM FOREST: MSE = %g\" % mseRF ) \n",
        "print(\"RANDOM FOREST + GRID SEARCH: MSE = %g\" % mseGS )\n",
        "print(\"GRADIENT BOOSTED TREE REGRESSOR: MSE = %g\" % mseGBT )\n",
        "print(\"LINEAR REGRESSION + DISCRETIZADOS:MSE = %g\" % mseLRD ) \n",
        "print(\"LINEAR REGRESSION: MSE = %g\" % mseLR )\n",
        "print(\"LINEAR REGRESSION + ESTANDARIZADOS: MSE = %g\" % mseLRE ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1vzhI4CUHYg",
        "outputId": "f6ca915e-cd34-41d6-e908-f0b660586a64"
      },
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANDOM FOREST: MSE = 1.05323e+09\n",
            "RANDOM FOREST + GRID SEARCH: MSE = 6.15758e+08\n",
            "GRADIENT BOOSTED TREE REGRESSOR: MSE = 3.04763e+07\n",
            "LINEAR REGRESSION + DISCRETIZADOS:MSE = 34.3973\n",
            "LINEAR REGRESSION: MSE = 27.8739\n",
            "LINEAR REGRESSION + ESTANDARIZADOS: MSE = 18.7641\n"
          ]
        }
      ]
    }
  ]
}